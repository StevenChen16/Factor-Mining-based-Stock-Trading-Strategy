{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于因子挖掘的机器学习股票交易策略\n",
    "\n",
    "本项目旨在通过机器学习和因子挖掘技术，开发一个高效的股票交易策略。我们的方法结合了传统的技术分析指标和先进的时间序列特征提取技术，以捕捉市场中潜在的alpha因子。\n",
    "\n",
    "项目流程包括：\n",
    "1. 数据获取与预处理：使用qstock库获取历史股票数据，并进行初步清理。\n",
    "2. 特征工程：利用TA-Lib计算传统技术指标，如RSI、MACD等。\n",
    "3. 因子挖掘：应用tsfresh库进行大规模时间序列特征提取，挖掘潜在的alpha因子。\n",
    "4. 模型训练：使用SVM或随机森林算法构建预测模型，识别最具预测力的因子组合。\n",
    "5. 策略回测：基于模型预测结果，构建交易策略并进行历史回测，评估策略的有效性。\n",
    "\n",
    "通过这个项目，我们旨在展示如何将现代数据科学技术应用于量化投资领域，以及如何系统地挖掘和验证潜在的alpha因子。这个方法不仅适用于个股分析，也可以扩展到更广泛的市场和资产类别。\n",
    "\n",
    "注意：本项目仅用于教育和研究目的，不构成任何投资建议。在实际交易中应用任何策略之前，都需要进行充分的风险评估和额外的验证。\n",
    "\n",
    "# Factor Mining-based Machine Learning Stock Trading Strategy\n",
    "\n",
    "This project aims to develop an efficient stock trading strategy using machine learning and factor mining techniques. Our approach combines traditional technical analysis indicators with advanced time series feature extraction methods to capture potential alpha factors in the market.\n",
    "\n",
    "The project workflow includes:\n",
    "1. Data Acquisition and Preprocessing: Using the qstock library to obtain historical stock data and perform initial cleaning.\n",
    "2. Feature Engineering: Utilizing TA-Lib to calculate traditional technical indicators such as RSI, MACD, etc.\n",
    "3. Factor Mining: Applying the tsfresh library for large-scale time series feature extraction to uncover potential alpha factors.\n",
    "4. Model Training: Building predictive models using SVM or Random Forest algorithms to identify the most predictive factor combinations.\n",
    "5. Strategy Backtesting: Constructing trading strategies based on model predictions and conducting historical backtests to evaluate strategy effectiveness.\n",
    "\n",
    "Through this project, we aim to demonstrate how modern data science techniques can be applied to quantitative investment, and how to systematically mine and validate potential alpha factors. This approach is not only applicable to individual stock analysis but can also be extended to broader markets and asset classes.\n",
    "\n",
    "Note: This project is for educational and research purposes only and does not constitute any investment advice. Before applying any strategy in actual trading, thorough risk assessment and additional validation are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据获取与预处理\n",
    "# Data Acquisition and Preprocessing\n",
    "\n",
    "这个单元格主要完成以下任务:\n",
    "1. 导入必要的库,如qstock用于获取股票数据。\n",
    "2. 使用qstock获取苹果公司(AAPL)的历史股价数据。\n",
    "3. 对数据进行基本的清理和预处理,包括删除不需要的列、处理缺失值、重置索引等。\n",
    "\n",
    "This cell performs the following tasks:\n",
    "1. Imports necessary libraries, such as qstock for fetching stock data.\n",
    "2. Uses qstock to obtain historical stock price data for Apple Inc. (AAPL).\n",
    "3. Performs basic data cleaning and preprocessing, including removing unnecessary columns, handling missing values, resetting the index, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qstock as qs\n",
    "\n",
    "# 获取沪深300指数高开低收、成交量、成交金额、换手率数据，index是日期\n",
    "# data = qs.get_data(code_list=['AAPL','NVDA','MSFT'], start='20050408', end='20240324', freq='d')\n",
    "data = qs.get_data(code_list=['AAPL'], start='20050408', end='20240324', freq='d')\n",
    "# 删除名称列、排序并去除空值\n",
    "data = data.drop(columns=['name']).sort_index().fillna(method='ffill').dropna()\n",
    "# 插入日期列\n",
    "data.insert(0, 'date', data.index)\n",
    "# 将日期从datetime格式转换为str格式\n",
    "data['date'] = data['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(data.shape)\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "# Feature Engineering\n",
    "\n",
    "这个单元格进行了以下操作:\n",
    "1. 使用talib库计算了多个技术指标,如斜率(slope)、相对强弱指标(RSI)、威廉指标(Williams %R)、MACD和抛物线SAR。\n",
    "2. 删除了一些原始列(开盘价、最高价、最低价),只保留计算出的指标和其他必要的列。\n",
    "3. 再次处理了可能出现的缺失值。\n",
    "\n",
    "This cell performs the following operations:\n",
    "1. Uses the talib library to calculate multiple technical indicators, such as slope, Relative Strength Index (RSI), Williams %R, MACD, and Parabolic SAR.\n",
    "2. Removes some original columns (open, high, low prices), keeping only the calculated indicators and other necessary columns.\n",
    "3. Handles any potential missing values that might have appeared after calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "# 收盘价的斜率\n",
    "data['slope'] = talib.LINEARREG_SLOPE(data['close'].values, timeperiod=5)\n",
    "# 相对强弱指标\n",
    "data['rsi'] = talib.RSI(data['close'].values, timeperiod = 14)\n",
    "# 威廉指标值\n",
    "data['wr'] = talib.WILLR(data['high'].values, data['low'].values, data['close'].values, timeperiod=7)\n",
    "# MACD中的DIF、DEA和MACD柱\n",
    "data['dif'], data['dea'], data['macd'] = talib.MACD(data['close'].values, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "# 抛物线指标\n",
    "data['sar'] = talib.SAR(data['high'].values, data['low'].values)\n",
    "# 删除开盘价、最高价和最低价\n",
    "data = data.drop(columns=['open','high','low']).fillna(method='ffill').dropna().reset_index(drop=True)\n",
    "\n",
    "print(data.shape)\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列特征提取\n",
    "# Time Series Feature Extraction\n",
    "\n",
    "这个单元格主要完成以下任务:\n",
    "1. 使用tsfresh库的roll_time_series函数对数据进行滚动处理,创建多个时间窗口的特征。\n",
    "2. 使用tsfresh的extract_features函数提取大量时间序列特征。\n",
    "3. 调整提取的特征的索引,使其与原始数据对应。\n",
    "\n",
    "This cell mainly accomplishes the following tasks:\n",
    "1. Uses the roll_time_series function from the tsfresh library to perform rolling window processing on the data, creating features for multiple time windows.\n",
    "2. Uses the extract_features function from tsfresh to extract a large number of time series features.\n",
    "3. Adjusts the index of the extracted features to correspond with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "\n",
    "data_roll = roll_time_series(data, column_id='code', column_sort='date', max_timeshift=20, min_timeshift=5).drop(columns=['code'])\n",
    "\n",
    "print(data_roll.shape)\n",
    "data_roll.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = data_roll.groupby('id').agg({'date':['count', min, max]})\n",
    "\n",
    "print(gg.shape)\n",
    "gg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "\n",
    "data_feat = extract_features(data_roll, column_id='id', column_sort='date')\n",
    "# 对单独标的而言，将日期作为index\n",
    "data_feat.index = [v[1] for v in data_feat.index] \n",
    "\n",
    "print(data_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "# Data Preparation\n",
    "\n",
    "这个单元格进行了以下操作:\n",
    "1. 将原始特征与通过tsfresh提取的特征合并。\n",
    "2. 创建目标变量:\n",
    "   - 'pct': 下一天的收益率\n",
    "   - 'rise': 二元分类变量,表示股价是否上涨\n",
    "3. 删除含有缺失值的行。\n",
    "\n",
    "This cell performs the following operations:\n",
    "1. Merges the original features with the features extracted through tsfresh.\n",
    "2. Creates target variables:\n",
    "   - 'pct': The next day's return rate\n",
    "   - 'rise': A binary classification variable indicating whether the stock price rose\n",
    "3. Removes rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将原始因子加入因子矩阵当中\n",
    "data_feat = pd.merge(data_feat, data.set_index('date', drop=True).drop(columns=['code']), \n",
    "                     how='left', left_index=True, right_index=True)\n",
    "\n",
    "# 给数据打标签\n",
    "data_feat['pct'] = data_feat['close'].shift(-1) / data_feat['close'] - 1.0\n",
    "data_feat['rise'] = data_feat['pct'].apply(lambda x: 1 if x>0 else 0)\n",
    "data_feat = data_feat.dropna(subset=['pct'])\n",
    "\n",
    "print(data_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "\n",
    "# 划分训练集和测试集\n",
    "num_train = round(len(data_feat)*0.8)\n",
    "data_train = data_feat.iloc[:num_train, :]\n",
    "y_train = data_feat.iloc[:num_train, :]['rise']\n",
    "data_test = data_feat.iloc[num_train:, :]\n",
    "y_test = data_feat.iloc[num_train:, :]['rise']\n",
    "\n",
    "# 特征选择\n",
    "data_train0 = select_features(data_train.drop(columns=['pct','rise']).dropna(axis=1, how='any'), y_train)\n",
    "select_columns = list(data_train0.columns) + ['pct','rise']\n",
    "data_train = data_train[select_columns]\n",
    "data_test = data_test[select_columns]\n",
    "\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "# Model Training\n",
    "\n",
    "这个单元格完成了以下任务:\n",
    "1. 将数据集分为训练集(80%)和测试集(20%)。\n",
    "2. 使用tsfresh的select_features函数进行特征选择。\n",
    "3. 使用SimpleImputer处理缺失值。\n",
    "4. 使用StandardScaler对特征进行标准化。\n",
    "5. 训练RandomForestClassifier模型。\n",
    "6. 在训练集和测试集上评估模型性能。\n",
    "7. 保存训练好的模型和selected特征名称。\n",
    "\n",
    "This cell accomplishes the following tasks:\n",
    "1. Splits the dataset into training (80%) and test (20%) sets.\n",
    "2. Uses the select_features function from tsfresh for feature selection.\n",
    "3. Handles missing values using SimpleImputer.\n",
    "4. Standardizes features using StandardScaler.\n",
    "5. Trains a RandomForestClassifier model.\n",
    "6. Evaluates model performance on both training and test sets.\n",
    "7. Saves the trained model and the names of selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 转化为numpy的ndarray数组格式\n",
    "X_train = data_train.drop(columns=['pct','rise']).values\n",
    "X_test = data_test.drop(columns=['pct','rise']).values\n",
    "\n",
    "# 对数据进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 训练模型\n",
    "classifier = SVC(C=1.0, kernel='rbf')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "data_train['pred'] = y_train_pred\n",
    "data_test['pred'] = y_test_pred\n",
    "accuracy_train = 100 * data_train[data_train.rise==data_train.pred].shape[0] / data_train.shape[0]\n",
    "accuracy_test = 100 * data_test[data_test.rise==data_test.pred].shape[0] / data_test.shape[0]\n",
    "print('训练集预测准确率：%.2f%%' %accuracy_train)\n",
    "print('测试集预测准确率：%.2f%%' %accuracy_test)\n",
    "\n",
    "import joblib\n",
    "# 保存模型\n",
    "joblib.dump(classifier, 'trained_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 转化为numpy的ndarray数组格式\n",
    "X_train = data_train.drop(columns=['pct', 'rise']).values\n",
    "X_test = data_test.drop(columns=['pct', 'rise']).values\n",
    "\n",
    "# 使用SimpleImputer填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# 对数据进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 训练模型\n",
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "data_train['pred'] = y_train_pred\n",
    "data_test['pred'] = y_test_pred\n",
    "accuracy_train = 100 * data_train[data_train.rise == data_train.pred].shape[0] / data_train.shape[0]\n",
    "accuracy_test = 100 * data_test[data_test.rise == data_test.pred].shape[0] / data_test.shape[0]\n",
    "print('训练集预测准确率：%.2f%%' % accuracy_train)\n",
    "print('测试集预测准确率：%.2f%%' % accuracy_test)\n",
    "\n",
    "import joblib\n",
    "# 保存模型\n",
    "joblib.dump(classifier, 'trained_model_rf.pkl')\n",
    "\n",
    "# 保存特征名称\n",
    "feature_names = data_train.drop(columns=['pct', 'rise']).columns\n",
    "joblib.dump(feature_names, 'feature_names.pkl')\n",
    "# 保存特征选择后的列名\n",
    "selected_feature_names = data_train.drop(columns=['pct', 'rise']).columns\n",
    "joblib.dump(selected_feature_names, 'selected_feature_names.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 策略回测\n",
    "# Strategy Backtesting\n",
    "\n",
    "这个单元格进行了以下操作:\n",
    "1. 基于模型预测结果计算策略收益。\n",
    "2. 计算策略和买入持有策略的累积收益。\n",
    "3. 计算策略的年化收益率。\n",
    "4. 绘制策略收益与买入持有策略的对比图。\n",
    "\n",
    "This cell performs the following operations:\n",
    "1. Calculates strategy returns based on model predictions.\n",
    "2. Computes cumulative returns for both the strategy and a buy-and-hold approach.\n",
    "3. Calculates the annualized return of the strategy.\n",
    "4. Plots a comparison of the strategy returns versus a buy-and-hold approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import talib\n",
    "import dill as pickle  # 使用 dill 代替 pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tsfresh import extract_features\n",
    "\n",
    "class PandasDataExtend(bt.feeds.PandasData):\n",
    "    lines = ('Slope', 'Rsi', 'Wr', 'Dif', 'Dea', 'Macd', 'Sar',)\n",
    "    params = (('Slope', -1), ('Rsi', -1), ('Wr', -1), ('Dif', -1), ('Dea', -1), ('Macd', -1), ('Sar', -1),)\n",
    "\n",
    "class MLStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.model = joblib.load('trained_model_rf.pkl')\n",
    "        self.selected_feature_names = joblib.load('selected_feature_names.pkl')\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "        self.scaler = StandardScaler()\n",
    "        initial_data = self.data_to_dataframe()\n",
    "        self.features = extract_features(initial_data, column_id='code', column_sort='date')\n",
    "        self.features = self.features.reindex(columns=self.selected_feature_names, fill_value=0)\n",
    "        self.imputer.fit(self.features)\n",
    "        self.scaler.fit(self.features)\n",
    "        self.extracted_features = {}\n",
    "        self.daily_value = []\n",
    "        self.trades = []\n",
    "\n",
    "    def data_to_dataframe(self):\n",
    "        data = {\n",
    "            'date': [self.data.datetime.date(0)],\n",
    "            'code': [self.data._name],\n",
    "            'Close': [self.data.close[0]],\n",
    "            'High': [self.data.high[0]],\n",
    "            'Low': [self.data.low[0]],\n",
    "            'Open': [self.data.open[0]],\n",
    "            'Volume': [self.data.volume[0]],\n",
    "        }\n",
    "        for name in self.params._getkeys():\n",
    "            data[name] = [getattr(self.data, name)[0]]\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def next(self):\n",
    "        current_date = self.data.datetime.date(0)\n",
    "        if current_date not in self.extracted_features:\n",
    "            current_data = self.data_to_dataframe()\n",
    "            current_features = extract_features(current_data, column_id='code', column_sort='date')\n",
    "            current_features = current_features.reindex(columns=self.selected_feature_names, fill_value=0)\n",
    "            current_features = self.imputer.transform(current_features)\n",
    "            current_features = self.scaler.transform(current_features)\n",
    "            self.extracted_features[current_date] = current_features\n",
    "        else:\n",
    "            current_features = self.extracted_features[current_date]\n",
    "        prediction = self.model.predict(current_features)\n",
    "        if prediction == 1 and not self.position:\n",
    "            self.buy()\n",
    "            self.trades.append((current_date, 'buy', self.data.close[0]))\n",
    "        elif prediction == 0 and self.position:\n",
    "            self.sell()\n",
    "            self.trades.append((current_date, 'sell', self.data.close[0]))\n",
    "        self.daily_value.append((current_date, self.broker.getvalue()))\n",
    "\n",
    "dataframe = pd.read_csv('AAPL.csv', index_col='Date', parse_dates=True)\n",
    "dataframe['Slope'] = talib.LINEARREG_SLOPE(dataframe['Close'].values, timeperiod=5)\n",
    "dataframe['Rsi'] = talib.RSI(dataframe['Close'].values, timeperiod=14)\n",
    "dataframe['Wr'] = talib.WILLR(dataframe['High'].values, dataframe['Low'].values, dataframe['Close'].values, timeperiod=7)\n",
    "dataframe['Dif'], dataframe['Dea'], dataframe['Macd'] = talib.MACD(dataframe['Close'].values, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "dataframe['Sar'] = talib.SAR(dataframe['High'].values, dataframe['Low'].values)\n",
    "dataframe = dataframe.dropna()\n",
    "\n",
    "cerebro = bt.Cerebro()\n",
    "cerebro.addstrategy(MLStrategy)\n",
    "data = PandasDataExtend(dataname=dataframe)\n",
    "cerebro.adddata(data)\n",
    "cerebro.broker.set_cash(10000)\n",
    "cerebro.addsizer(bt.sizers.FixedSize, stake=10)\n",
    "cerebro.broker.setcommission(commission=0.001)\n",
    "\n",
    "print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "cerebro.run()\n",
    "print('Ending Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "\n",
    "cerebro.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cerebro.plot(dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0][0].savefig('AAPL1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
